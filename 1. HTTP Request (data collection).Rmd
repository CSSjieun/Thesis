---
title: "Code for the thesis"
author: "Jieun Park"
date: "`r Sys.Date()`"
output: html_document
---

# Data Collection

## Authentication

```{r}
# Initialize variables
cursor <- "*"  # Initial cursor value
resp_list <- list()  # List to store responses
resp_counter <- 1  # Counter for response names

# Loop to make API requests
while (TRUE) {
  # Create query parameters
  query_params <- list(
    count = 25,
    query = "SRCTYPE(j) AND AF-ID(60001741) AND SUBJAREA(ARTS)",
    date = "2014-2024",
    apiKey = X_ELS_APIKey,
    httpAccept = "application/json",
    cursor = cursor,
    "User-Agent" = "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
    view = "COMPLETE",
    facets = "authname;autcite"
  )
  
  # Make API call
  api_call <- GET(url = scopus_url, query = query_params)
  
  # Check status code
  if (status_code(api_call) != 200) {
    print("Error: API request failed.")
    break
  }
  
  # Get response JSON
  response_json <- content(api_call, as = "text", encoding = "UTF-8")
  
  # Parse JSON response
  resp <- fromJSON(response_json)
  
  # Check if there are search results
  if ("search-results" %in% names(resp) && "entry" %in% names(resp$`search-results`)) {
    # Assign cursor value with appropriate response name
    cursor <- resp$`search-results`$cursor$`@next`
    
    # Store response in the list with appropriate name
    resp_list[[paste0("resp", resp_counter)]] <- resp
    
    # Update counter for the next response name
    resp_counter <- resp_counter + 1
  } else {
    # No more data to collect
    break
  }
  
  # Wait for 2 seconds before the next request
  Sys.sleep(2)
}

length(resp_list)



# Initialize an empty list to store data frames
dfs <- list()

# Loop through each element in resp_list
for (i in 1:37) {
  # Extract the 'search-results' and 'entry' from the current response
  df <- resp_list[[i]]$`search-results`$entry
  
  # Reset row names of df
  rownames(df) <- NULL
  
  # Store the data frame in the list
  dfs[[i]] <- df
}
```

# HTTP GET REQUEST

## Library for HTTP request and basic components for using RESTful API

```{r}
library(httr)
library(httr2)
library(jsonlite)

# API key
X_ELS_APIKey <- ""
# scopus_url
scopus_url = "http://api.elsevier.com/content/search/scopus"
```


## Arts and Humanities

### HTTP GET Request 

```{r}
# Initialize variables
cursor <- "*"  # Initial cursor value
resp_list <- list()  # List to store responses
resp_counter <- 1  # Counter for response names

# Loop to make API requests
while (TRUE) {
  # Create query parameters
  query_params <- list(
    count = 25,
    query = "SRCTYPE(j) AND AF-ID(60001741) AND SUBJAREA(ARTS)",
    date = "2014-2024",
    apiKey = X_ELS_APIKey,
    httpAccept = "application/json",
    cursor = cursor,
    "User-Agent" = "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
    view = "COMPLETE"
  )
  
  # Make API call
  api_call <- GET(url = scopus_url, query = query_params)
  
  # Check status code
  if (status_code(api_call) != 200) {
    print("Error: API request failed.")
    break
  }
  
  # Get response JSON
  response_json <- content(api_call, as = "text", encoding = "UTF-8")
  
  # Parse JSON response
  resp <- fromJSON(response_json)
  
  # Check if there are search results
  if ("search-results" %in% names(resp) && "entry" %in% names(resp$`search-results`)) {
    # Assign cursor value with appropriate response name
    cursor <- resp$`search-results`$cursor$`@next`
    
    # Store response in the list with appropriate name
    resp_list[[paste0("resp", resp_counter)]] <- resp
    
    # Update counter for the next response name
    resp_counter <- resp_counter + 1
  } else {
    # No more data to collect
    break
  }
  
  # Wait for 2 seconds before the next request
  Sys.sleep(2)
}
```


### Taking only useful dataset

```{r}
# Initialize an empty list to store data frames
dfs <- list()

# Loop through each element in resp_list
for (i in seq_along(resp_list)) {
  # Extract the 'search-results' and 'entry' from the current response
  df <- resp_list[[i]]$`search-results`$entry
  
  # Reset row names of df
  rownames(df) <- NULL
  
  # Store the data frame in the list
  dfs[[i]] <- df
}
```

### Filtering useful information (1)

```{r}
library(dplyr)
library(tidyr)

# Initialize an empty list to store processed data frames
processed_dfs <- list()

# Iterate over each data frame in dfs
for (i in seq_along(dfs)) {
  # Select the specified columns
  selected_cols <- dfs[[i]][c("dc:title", "prism:publicationName", "author",
                              "prism:coverDate")]
  
  # Unnest the author column
  processed_df <- selected_cols %>%
    unnest(author)
  
  # Append the processed data frame to the list
  processed_dfs[[i]] <- processed_df
}
```

### Filtering useful information (2)

```{r}
library(dplyr)

# Initialize an empty list to store processed data frames
processed_dfs_2 <- list()

# Iterate over each data frame in processed_dfs
for (i in seq_along(processed_dfs)) {
  # Select the specified columns
  selected_cols <- processed_dfs[[i]][c("@seq", "dc:title", "authid", "authname",
                                        "prism:publicationName", "prism:coverDate")]
  
  # Append the processed data frame to the list
  processed_dfs_2[[i]] <- selected_cols
}
```

### Merge them

```{r}
# Combine all processed data frames into a single data frame
combined_df_2 <- do.call(rbind, processed_dfs_2)

combined_df_2 <- combined_df_2 %>%
  mutate(
    collaboration_group = cumsum(str_detect(as.character(combined_df_2[["@seq"]]), "\\b1\\b")),
    .before = "@seq"
  )

colnames(combined_df_2)[2] <- "sequence"
colnames(combined_df_2)[3] <- "title"
colnames(combined_df_2)[6] <- "journal_name"
colnames(combined_df_2)[7] <- "date"

# Convert the date variable to a Date object
combined_df_2$date <- as.Date(combined_df_2$date)

# Extract the year from the date variable
combined_df_2$date <- format(combined_df_2$date, "%Y")

combined_df_2
```

### Save as .csv file

```{r}
write.csv(combined_df_2, file = "data_ARTS.csv", row.names = FALSE)
```

## Social Science

### Loop for data collection

```{r}
rm(list=ls())
# Initialize variables
cursor <- "*"  # Initial cursor value
resp_list <- list()  # List to store responses
resp_counter <- 1  # Counter for response names

# Loop to make API requests
while (TRUE) {
  # Create query parameters
  query_params <- list(
    count = 25,
    query = "SRCTYPE(j) AND AF-ID(60001741) AND SUBJAREA(SOCI)",
    date = "2014-2024",
    apiKey = X_ELS_APIKey,
    httpAccept = "application/json",
    cursor = cursor,
    "User-Agent" = "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
    view = "COMPLETE",
    facets = "authname;autcite"
  )
  
  # Make API call
  api_call <- GET(url = scopus_url, query = query_params)
  
  # Check status code
  if (status_code(api_call) != 200) {
    print("Error: API request failed.")
    break
  }
  
  # Get response JSON
  response_json <- content(api_call, as = "text", encoding = "UTF-8")
  
  # Parse JSON response
  resp <- fromJSON(response_json)
  
  # Check if there are search results
  if ("search-results" %in% names(resp) && "entry" %in% names(resp$`search-results`)) {
    # Assign cursor value with appropriate response name
    cursor <- resp$`search-results`$cursor$`@next`
    
    # Store response in the list with appropriate name
    resp_list[[paste0("resp", resp_counter)]] <- resp
    
    # Update counter for the next response name
    resp_counter <- resp_counter + 1
  } else {
    # No more data to collect
    break
  }
  
  # Wait for 2 seconds before the next request
  Sys.sleep(2)
}
```

### Taking only useful dataset

```{r}
# Initialize an empty list to store data frames
dfs <- list()

# Loop through each element in resp_list
for (i in seq_along(resp_list)) {
  # Extract the 'search-results' and 'entry' from the current response
  df <- resp_list[[i]]$`search-results`$entry
  
  # Reset row names of df
  rownames(df) <- NULL
  
  # Store the data frame in the list
  dfs[[i]] <- df
}
```

### Filtering useful information (1)

```{r}
library(dplyr)
library(tidyr)

# Initialize an empty list to store processed data frames
processed_dfs <- list()

# Iterate over each data frame in dfs
for (i in seq_along(dfs)) {
  # Select the specified columns
  selected_cols <- dfs[[i]][c("dc:title", "prism:publicationName", "author",
                              "prism:coverDate")]
  
  # Unnest the author column
  processed_df <- selected_cols %>%
    unnest(author)
  
  # Append the processed data frame to the list
  processed_dfs[[i]] <- processed_df
}
```

### Filtering useful information (2)

```{r}
library(dplyr)

# Initialize an empty list to store processed data frames
processed_dfs_2 <- list()

# Iterate over each data frame in processed_dfs
for (i in seq_along(processed_dfs)) {
  # Select the specified columns
  selected_cols <- processed_dfs[[i]][c("@seq", "dc:title", "authid", "authname",
                                        "prism:publicationName",  "prism:coverDate")]
  
  # Append the processed data frame to the list
  processed_dfs_2[[i]] <- selected_cols
}
```

### Merge them

```{r}
# Combine all processed data frames into a single data frame
combined_df_2 <- do.call(rbind, processed_dfs_2)

combined_df_2 <- combined_df_2 %>%
  mutate(
    collaboration_group = cumsum(str_detect(as.character(combined_df_2[["@seq"]]), "\\b1\\b")),
    .before = "@seq"
  )

colnames(combined_df_2)[2] <- "sequence"
colnames(combined_df_2)[3] <- "title"
colnames(combined_df_2)[6] <- "journal_name"
colnames(combined_df_2)[7] <- "date"

# Convert the date variable to a Date object
combined_df_2$date <- as.Date(combined_df_2$date)

# Extract the year from the date variable
combined_df_2$date <- format(combined_df_2$date, "%Y")

combined_df_2
```

### Save as .csv file

```{r}
write.csv(combined_df_2, file = "data_SOCI.csv", row.names = FALSE)
```

## Computer Science

### Loop for data collection

```{r}
rm(list=ls())
# Initialize variables
cursor <- "*"  # Initial cursor value
resp_list <- list()  # List to store responses
resp_counter <- 1  # Counter for response names

# Loop to make API requests
while (TRUE) {
  # Create query parameters
  query_params <- list(
    count = 25,
    query = "SRCTYPE(j) AND AF-ID(60001741) AND SUBJAREA(COMP)",
    date = "2014-2024",
    apiKey = X_ELS_APIKey,
    httpAccept = "application/json",
    cursor = cursor,
    "User-Agent" = "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
    view = "COMPLETE",
    facets = "authname;autcite"
  )
  
  # Make API call
  api_call <- GET(url = scopus_url, query = query_params)
  
  # Check status code
  if (status_code(api_call) != 200) {
    print("Error: API request failed.")
    break
  }
  
  # Get response JSON
  response_json <- content(api_call, as = "text", encoding = "UTF-8")
  
  # Parse JSON response
  resp <- fromJSON(response_json)
  
  # Check if there are search results
  if ("search-results" %in% names(resp) && "entry" %in% names(resp$`search-results`)) {
    # Assign cursor value with appropriate response name
    cursor <- resp$`search-results`$cursor$`@next`
    
    # Store response in the list with appropriate name
    resp_list[[paste0("resp", resp_counter)]] <- resp
    
    # Update counter for the next response name
    resp_counter <- resp_counter + 1
  } else {
    # No more data to collect
    break
  }
  
  # Wait for 2 seconds before the next request
  Sys.sleep(2)
}
```

### Taking only useful dataset

```{r}
# Initialize an empty list to store data frames
dfs <- list()

# Loop through each element in resp_list
for (i in seq_along(resp_list)) {
  # Extract the 'search-results' and 'entry' from the current response
  df <- resp_list[[i]]$`search-results`$entry
  
  # Reset row names of df
  rownames(df) <- NULL
  
  # Store the data frame in the list
  dfs[[i]] <- df
}
```

### Filtering useful information (1)

```{r}
library(dplyr)
library(tidyr)

# Initialize an empty list to store processed data frames
processed_dfs <- list()

# Iterate over each data frame in dfs
for (i in seq_along(dfs)) {
  # Select the specified columns
  selected_cols <- dfs[[i]][c("dc:title", "prism:publicationName", "author",
                              "prism:coverDate")]
  
  # Unnest the author column
  processed_df <- selected_cols %>%
    unnest(author)
  
  # Append the processed data frame to the list
  processed_dfs[[i]] <- processed_df
}
```

### Filtering useful information (2)

```{r}
library(dplyr)

# Initialize an empty list to store processed data frames
processed_dfs_2 <- list()

# Iterate over each data frame in processed_dfs
for (i in seq_along(processed_dfs)) {
  # Select the specified columns
  selected_cols <- processed_dfs[[i]][c("@seq", "dc:title", "authid", "authname",
                                        "prism:publicationName",  "prism:coverDate")]
  
  # Append the processed data frame to the list
  processed_dfs_2[[i]] <- selected_cols
}
```

### Merge them

```{r}
# Combine all processed data frames into a single data frame
combined_df_2 <- do.call(rbind, processed_dfs_2)

combined_df_2 <- combined_df_2 %>%
  mutate(
    collaboration_group = cumsum(str_detect(as.character(combined_df_2[["@seq"]]), "\\b1\\b")),
    .before = "@seq"
  )

colnames(combined_df_2)[2] <- "sequence"
colnames(combined_df_2)[3] <- "title"
colnames(combined_df_2)[6] <- "journal_name"
colnames(combined_df_2)[7] <- "date"

# Convert the date variable to a Date object
combined_df_2$date <- as.Date(combined_df_2$date)

# Extract the year from the date variable
combined_df_2$date <- format(combined_df_2$date, "%Y")

combined_df_2
```

### Save as .csv file

```{r}
write.csv(combined_df_2, file = "data_COMP.csv", row.names = FALSE)
```

## Engineering

### Loop for data collection

```{r}
rm(list=ls())
# Initialize variables
cursor <- "*"  # Initial cursor value
resp_list <- list()  # List to store responses
resp_counter <- 1  # Counter for response names

# Loop to make API requests
while (TRUE) {
  # Create query parameters
  query_params <- list(
    count = 25,
    query = "SRCTYPE(j) AND AF-ID(60001741) AND SUBJAREA(ENGI)",
    date = "2014-2024",
    apiKey = X_ELS_APIKey,
    httpAccept = "application/json",
    cursor = cursor,
    "User-Agent" = "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
    view = "COMPLETE",
    facets = "authname;autcite"
  )
  
  # Make API call
  api_call <- GET(url = scopus_url, query = query_params)
  
  # Check status code
  if (status_code(api_call) != 200) {
    print("Error: API request failed.")
    break
  }
  
  # Get response JSON
  response_json <- content(api_call, as = "text", encoding = "UTF-8")
  
  # Parse JSON response
  resp <- fromJSON(response_json)
  
  # Check if there are search results
  if ("search-results" %in% names(resp) && "entry" %in% names(resp$`search-results`)) {
    # Assign cursor value with appropriate response name
    cursor <- resp$`search-results`$cursor$`@next`
    
    # Store response in the list with appropriate name
    resp_list[[paste0("resp", resp_counter)]] <- resp
    
    # Update counter for the next response name
    resp_counter <- resp_counter + 1
  } else {
    # No more data to collect
    break
  }
  
  # Wait for 2 seconds before the next request
  Sys.sleep(2)
}
```

### Taking only useful dataset

```{r}
# Initialize an empty list to store data frames
dfs <- list()

# Loop through each element in resp_list
for (i in seq_along(resp_list)) {
  # Extract the 'search-results' and 'entry' from the current response
  df <- resp_list[[i]]$`search-results`$entry
  
  # Reset row names of df
  rownames(df) <- NULL
  
  # Store the data frame in the list
  dfs[[i]] <- df
}
```

### Filtering useful information (1)

```{r}
library(dplyr)
library(tidyr)

# Initialize an empty list to store processed data frames
processed_dfs <- list()

# Iterate over each data frame in dfs
for (i in seq_along(dfs)) {
  # Select the specified columns
  selected_cols <- dfs[[i]][c("dc:title", "prism:publicationName", "author",
                              "prism:coverDate")]
  
  # Unnest the author column
  processed_df <- selected_cols %>%
    unnest(author)
  
  # Append the processed data frame to the list
  processed_dfs[[i]] <- processed_df
}
```

### Filtering useful information (2)

```{r}
library(dplyr)

# Initialize an empty list to store processed data frames
processed_dfs_2 <- list()

# Iterate over each data frame in processed_dfs
for (i in seq_along(processed_dfs)) {
  # Select the specified columns
  selected_cols <- processed_dfs[[i]][c("@seq", "dc:title", "authid", "authname",
                                        "prism:publicationName", "prism:coverDate")]
  
  # Append the processed data frame to the list
  processed_dfs_2[[i]] <- selected_cols
}
```

### Merge them

```{r}
# Combine all processed data frames into a single data frame
combined_df_2 <- do.call(rbind, processed_dfs_2)

combined_df_2 <- combined_df_2 %>%
  mutate(
    collaboration_group = cumsum(str_detect(as.character(combined_df_2[["@seq"]]), "\\b1\\b")),
    .before = "@seq"
  )

colnames(combined_df_2)[2] <- "sequence"
colnames(combined_df_2)[3] <- "title"
colnames(combined_df_2)[6] <- "journal_name"
colnames(combined_df_2)[7] <- "date"

# Convert the date variable to a Date object
combined_df_2$date <- as.Date(combined_df_2$date)

# Extract the year from the date variable
combined_df_2$date <- format(combined_df_2$date, "%Y")
combined_df_2
```

### Save as .csv file

```{r}
write.csv(combined_df_2, file = "data_ENGI.csv", row.names = FALSE)
```

## Mathematics

### Loop for data collection

```{r}
rm(list=ls())
# Initialize variables
cursor <- "*"  # Initial cursor value
resp_list <- list()  # List to store responses
resp_counter <- 1  # Counter for response names

# Loop to make API requests
while (TRUE) {
  # Create query parameters
  query_params <- list(
    count = 25,
    query = "SRCTYPE(j) AND AF-ID(60001741) AND SUBJAREA(MATH)",
    date = "2014-2024",
    apiKey = X_ELS_APIKey,
    httpAccept = "application/json",
    cursor = cursor,
    "User-Agent" = "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
    view = "COMPLETE",
    facets = "authname;autcite"
  )
  
  # Make API call
  api_call <- GET(url = scopus_url, query = query_params)
  
  # Check status code
  if (status_code(api_call) != 200) {
    print("Error: API request failed.")
    break
  }
  
  # Get response JSON
  response_json <- content(api_call, as = "text", encoding = "UTF-8")
  
  # Parse JSON response
  resp <- fromJSON(response_json)
  
  # Check if there are search results
  if ("search-results" %in% names(resp) && "entry" %in% names(resp$`search-results`)) {
    # Assign cursor value with appropriate response name
    cursor <- resp$`search-results`$cursor$`@next`
    
    # Store response in the list with appropriate name
    resp_list[[paste0("resp", resp_counter)]] <- resp
    
    # Update counter for the next response name
    resp_counter <- resp_counter + 1
  } else {
    # No more data to collect
    break
  }
  
  # Wait for 2 seconds before the next request
  Sys.sleep(2)
}
```

### Taking only useful dataset

```{r}
# Initialize an empty list to store data frames
dfs <- list()

# Loop through each element in resp_list
for (i in seq_along(resp_list)) {
  # Extract the 'search-results' and 'entry' from the current response
  df <- resp_list[[i]]$`search-results`$entry
  
  # Reset row names of df
  rownames(df) <- NULL
  
  # Store the data frame in the list
  dfs[[i]] <- df
}
```

### Filtering useful information (1)

```{r}
library(dplyr)
library(tidyr)

# Initialize an empty list to store processed data frames
processed_dfs <- list()

# Iterate over each data frame in dfs
for (i in seq_along(dfs)) {
  # Select the specified columns
  selected_cols <- dfs[[i]][c("dc:title", "prism:publicationName", "author",
                              "prism:coverDate")]
  
  # Unnest the author column
  processed_df <- selected_cols %>%
    unnest(author)
  
  # Append the processed data frame to the list
  processed_dfs[[i]] <- processed_df
}
```

### Filtering useful information (2)

```{r}
library(dplyr)

# Initialize an empty list to store processed data frames
processed_dfs_2 <- list()

# Iterate over each data frame in processed_dfs
for (i in seq_along(processed_dfs)) {
  # Select the specified columns
  selected_cols <- processed_dfs[[i]][c("@seq", "dc:title", "authid", "authname",
                                        "prism:publicationName",  "prism:coverDate")]
  
  # Append the processed data frame to the list
  processed_dfs_2[[i]] <- selected_cols
}
```

### Merge them

```{r}
# Combine all processed data frames into a single data frame
combined_df_2 <- do.call(rbind, processed_dfs_2)

combined_df_2 <- combined_df_2 %>%
  mutate(
    collaboration_group = cumsum(str_detect(as.character(combined_df_2[["@seq"]]), "\\b1\\b")),
    .before = "@seq"
  )

colnames(combined_df_2)[2] <- "sequence"
colnames(combined_df_2)[3] <- "title"
colnames(combined_df_2)[6] <- "journal_name"
colnames(combined_df_2)[7] <- "date"

# Convert the date variable to a Date object
combined_df_2$date <- as.Date(combined_df_2$date)

# Extract the year from the date variable
combined_df_2$date <- format(combined_df_2$date, "%Y")
combined_df_2
```

### Save as .csv file

```{r}
write.csv(combined_df_2, file = "data_MATH.csv", row.names = FALSE)
```

## Physics

### Loop for data collection

```{r}
rm(list=ls())
# Initialize variables
cursor <- "*"  # Initial cursor value
resp_list <- list()  # List to store responses
resp_counter <- 1  # Counter for response names

# Loop to make API requests
while (TRUE) {
  # Create query parameters
  query_params <- list(
    count = 25,
    query = "SRCTYPE(j) AND AF-ID(60001741) AND SUBJAREA(PHYS)",
    date = "2014-2024",
    apiKey = X_ELS_APIKey,
    httpAccept = "application/json",
    cursor = cursor,
    "User-Agent" = "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
    view = "COMPLETE",
    facets = "authname;autcite"
  )
  
  # Make API call
  api_call <- GET(url = scopus_url, query = query_params)
  
  # Check status code
  if (status_code(api_call) != 200) {
    print("Error: API request failed.")
    break
  }
  
  # Get response JSON
  response_json <- content(api_call, as = "text", encoding = "UTF-8")
  
  # Parse JSON response
  resp <- fromJSON(response_json)
  
  # Check if there are search results
  if ("search-results" %in% names(resp) && "entry" %in% names(resp$`search-results`)) {
    # Assign cursor value with appropriate response name
    cursor <- resp$`search-results`$cursor$`@next`
    
    # Store response in the list with appropriate name
    resp_list[[paste0("resp", resp_counter)]] <- resp
    
    # Update counter for the next response name
    resp_counter <- resp_counter + 1
  } else {
    # No more data to collect
    break
  }
  
  # Wait for 2 seconds before the next request
  Sys.sleep(2)
}
```

### Taking only useful dataset

```{r}
# Initialize an empty list to store data frames
dfs <- list()

# Loop through each element in resp_list
for (i in seq_along(resp_list)) {
  # Extract the 'search-results' and 'entry' from the current response
  df <- resp_list[[i]]$`search-results`$entry
  
  # Reset row names of df
  rownames(df) <- NULL
  
  # Store the data frame in the list
  dfs[[i]] <- df
}
```

### Filtering useful information (1)

```{r}
library(dplyr)
library(tidyr)

# Initialize an empty list to store processed data frames
processed_dfs <- list()

# Iterate over each data frame in dfs
for (i in seq_along(dfs)) {
  # Select the specified columns
  selected_cols <- dfs[[i]][c("dc:title", "prism:publicationName", "author",
                              "prism:coverDate")]
  
  # Unnest the author column
  processed_df <- selected_cols %>%
    unnest(author)
  
  # Append the processed data frame to the list
  processed_dfs[[i]] <- processed_df
}
```

### Filtering useful information (2)

```{r}
library(dplyr)

# Initialize an empty list to store processed data frames
processed_dfs_2 <- list()

# Iterate over each data frame in processed_dfs
for (i in seq_along(processed_dfs)) {
  # Select the specified columns
  selected_cols <- processed_dfs[[i]][c("@seq", "dc:title", "authid", "authname",
                                        "prism:publicationName",  "prism:coverDate")]
  
  # Append the processed data frame to the list
  processed_dfs_2[[i]] <- selected_cols
}
```

### Merge them

```{r}
# Combine all processed data frames into a single data frame
combined_df_2 <- do.call(rbind, processed_dfs_2)

combined_df_2 <- combined_df_2 %>%
  mutate(
    collaboration_group = cumsum(str_detect(as.character(combined_df_2[["@seq"]]), "\\b1\\b")),
    .before = "@seq"
  )

colnames(combined_df_2)[2] <- "sequence"
colnames(combined_df_2)[3] <- "title"
colnames(combined_df_2)[6] <- "journal_name"
colnames(combined_df_2)[7] <- "date"

# Convert the date variable to a Date object
combined_df_2$date <- as.Date(combined_df_2$date)

# Extract the year from the date variable
combined_df_2$date <- format(combined_df_2$date, "%Y")
combined_df_2
```

### Save as .csv file

```{r}
write.csv(combined_df_2, file = "data_PHYS.csv", row.names = FALSE)
```






